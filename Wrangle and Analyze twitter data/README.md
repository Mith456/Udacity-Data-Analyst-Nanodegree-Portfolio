# Wrangle and Analyze Twitter Data

## Introduction
Data Wrangling consist of three stages : 1) Gathering 2) Assessing 3) Cleaning.
As a Data Scientist/ Analyst, this wrangling effort comes into action when dealing with huge chunks of dirty real-time data. With extensive use of pythonâ€™s powerful library tools, we wrangle the data to generate a master clean dataset that is ready for effective analysis.

## Twitter data
WeRateDogs gave Udacity access to their twitter archive in the form of a CSV file. This twitter archive contained basic tweet information like Tweet ID, text etc.. not enough for effective analysis. Additional interesting data was gathered by querying twitter's API using each tweet's JSON data through tweet ID. The data obtained was assessed to detect quality and tidiness issues, followed by cleaning the data.
The master dataframe obtained was then subjected to extensive analysis to generate insights from the data.

Code file: Wrangle_act.ipynb
This is the main project file with my code and a brief description of successive stages.
